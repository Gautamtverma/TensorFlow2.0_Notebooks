{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Classifier with Mini-Batch Gradient Descent\n",
    "\n",
    "#### Author: Ivan Bongiorni, Data Scientist at GfK.\n",
    "\n",
    "[LinkedIn profile](https://www.linkedin.com/in/ivan-bongiorni-b8a583164/)\n",
    "\n",
    "This model is a **feed forward Neural Network Classifier** based on the classical **spam dataset**.\n",
    "\n",
    "It represents a tutorial on basic TensorFlow 2.0 (alpha). The 1.x version of the same model can be found in [this Notebook](https://github.com/IvanBongiorni/TensorFlow_Tutorial/blob/master/TensorFlow_2_Classification_MiniBatchGD.ipynb).\n",
    "\n",
    "Summary:\n",
    "\n",
    "0. Why Mini-Batch Gradient Descent?\n",
    "1. Import data + dataprep,\n",
    "2. Neural Network architecture,\n",
    "3. Implementation of full-Batch Gradient Descent,\n",
    "4. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Why Mini-Batch Gradient Descent?\n",
    "\n",
    "**Mini-Batch Gradient Descent** is of fundamental importance for Deep Learning.\n",
    "\n",
    "It consists in feeding, at each iteration of the Gradient Descent, only a subset of (i.e.: a mini-batch) of the training data. At each iteration, mini-batch gradient descent will take a different mini-batch of data, and train just on that one.\n",
    "\n",
    "This technique presents at least three advantages:\n",
    "\n",
    "- It prevents the optimization algorithm to end up stuck into some local optima of the loss function.\n",
    "- It allows for a significant drop in computational times. That is because the optimizer trains the network just on a mini-batch of data, requiring much less effort. Often Data Scientists are dealing with massive amounts of data, and training a model on the whole train dataset at each epoch might simply be impossible.\n",
    "- It is the mandatory technique for [online learning](https://en.wikipedia.org/wiki/Online_machine_learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-alpha0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None  # this prints all columns\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import data + dataprep\n",
    "\n",
    "The **spam classification dataset**, [available from the UCI ML repository](https://archive.ics.uci.edu/ml/datasets/spambase) contains an already preprocessed collection of email data. Each datapoint corresponds to an email, and is classified as either \"spam\" or \"not spam\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601, 58)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data directly from the repository into pandas\n",
    "\n",
    "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\", header=None)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7     8     9     10    11  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  0.00  0.64   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  0.21  0.79   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  0.38  0.45   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  0.31  0.31   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  0.31  0.31   \n",
       "\n",
       "     12    13    14    15    16    17    18    19    20   21    22    23   24  \\\n",
       "0  0.00  0.00  0.00  0.32  0.00  1.29  1.93  0.00  0.96  0.0  0.00  0.00  0.0   \n",
       "1  0.65  0.21  0.14  0.14  0.07  0.28  3.47  0.00  1.59  0.0  0.43  0.43  0.0   \n",
       "2  0.12  0.00  1.75  0.06  0.06  1.03  1.36  0.32  0.51  0.0  1.16  0.06  0.0   \n",
       "3  0.31  0.00  0.00  0.31  0.00  0.00  3.18  0.00  0.31  0.0  0.00  0.00  0.0   \n",
       "4  0.31  0.00  0.00  0.31  0.00  0.00  3.18  0.00  0.31  0.0  0.00  0.00  0.0   \n",
       "\n",
       "    25   26   27   28   29   30   31   32   33   34   35    36   37   38  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.07  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.00  0.0  0.0   \n",
       "\n",
       "     39   40   41    42   43    44    45   46   47    48     49   50     51  \\\n",
       "0  0.00  0.0  0.0  0.00  0.0  0.00  0.00  0.0  0.0  0.00  0.000  0.0  0.778   \n",
       "1  0.00  0.0  0.0  0.00  0.0  0.00  0.00  0.0  0.0  0.00  0.132  0.0  0.372   \n",
       "2  0.06  0.0  0.0  0.12  0.0  0.06  0.06  0.0  0.0  0.01  0.143  0.0  0.276   \n",
       "3  0.00  0.0  0.0  0.00  0.0  0.00  0.00  0.0  0.0  0.00  0.137  0.0  0.137   \n",
       "4  0.00  0.0  0.0  0.00  0.0  0.00  0.00  0.0  0.0  0.00  0.135  0.0  0.135   \n",
       "\n",
       "      52     53     54   55    56  57  \n",
       "0  0.000  0.000  3.756   61   278   1  \n",
       "1  0.180  0.048  5.114  101  1028   1  \n",
       "2  0.184  0.010  9.821  485  2259   1  \n",
       "3  0.000  0.000  3.537   40   191   1  \n",
       "4  0.000  0.000  3.537   40   191   1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>0.059824</td>\n",
       "      <td>0.541702</td>\n",
       "      <td>0.093930</td>\n",
       "      <td>0.058626</td>\n",
       "      <td>0.049205</td>\n",
       "      <td>0.248848</td>\n",
       "      <td>0.142586</td>\n",
       "      <td>0.184745</td>\n",
       "      <td>1.662100</td>\n",
       "      <td>0.085577</td>\n",
       "      <td>0.809761</td>\n",
       "      <td>0.121202</td>\n",
       "      <td>0.101645</td>\n",
       "      <td>0.094269</td>\n",
       "      <td>0.549504</td>\n",
       "      <td>0.265384</td>\n",
       "      <td>0.767305</td>\n",
       "      <td>0.124845</td>\n",
       "      <td>0.098915</td>\n",
       "      <td>0.102852</td>\n",
       "      <td>0.064753</td>\n",
       "      <td>0.047048</td>\n",
       "      <td>0.097229</td>\n",
       "      <td>0.047835</td>\n",
       "      <td>0.105412</td>\n",
       "      <td>0.097477</td>\n",
       "      <td>0.136953</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.078629</td>\n",
       "      <td>0.064834</td>\n",
       "      <td>0.043667</td>\n",
       "      <td>0.132339</td>\n",
       "      <td>0.046099</td>\n",
       "      <td>0.079196</td>\n",
       "      <td>0.301224</td>\n",
       "      <td>0.179824</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>0.031869</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>283.289285</td>\n",
       "      <td>0.394045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305358</td>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>0.644755</td>\n",
       "      <td>0.201545</td>\n",
       "      <td>0.861698</td>\n",
       "      <td>0.301036</td>\n",
       "      <td>0.335184</td>\n",
       "      <td>0.258843</td>\n",
       "      <td>0.825792</td>\n",
       "      <td>0.444055</td>\n",
       "      <td>0.531122</td>\n",
       "      <td>1.775481</td>\n",
       "      <td>0.509767</td>\n",
       "      <td>1.200810</td>\n",
       "      <td>1.025756</td>\n",
       "      <td>0.350286</td>\n",
       "      <td>0.442636</td>\n",
       "      <td>1.671349</td>\n",
       "      <td>0.886955</td>\n",
       "      <td>3.367292</td>\n",
       "      <td>0.538576</td>\n",
       "      <td>0.593327</td>\n",
       "      <td>0.456682</td>\n",
       "      <td>0.403393</td>\n",
       "      <td>0.328559</td>\n",
       "      <td>0.555907</td>\n",
       "      <td>0.329445</td>\n",
       "      <td>0.532260</td>\n",
       "      <td>0.402623</td>\n",
       "      <td>0.423451</td>\n",
       "      <td>0.220651</td>\n",
       "      <td>0.434672</td>\n",
       "      <td>0.349916</td>\n",
       "      <td>0.361205</td>\n",
       "      <td>0.766819</td>\n",
       "      <td>0.223812</td>\n",
       "      <td>0.621976</td>\n",
       "      <td>1.011687</td>\n",
       "      <td>0.911119</td>\n",
       "      <td>0.076274</td>\n",
       "      <td>0.285735</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>606.347851</td>\n",
       "      <td>0.488698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.276000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.640000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.706000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>2.610000</td>\n",
       "      <td>9.670000</td>\n",
       "      <td>5.550000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.410000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7.140000</td>\n",
       "      <td>9.090000</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>17.100000</td>\n",
       "      <td>5.450000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>20.830000</td>\n",
       "      <td>16.660000</td>\n",
       "      <td>33.330000</td>\n",
       "      <td>9.090000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>7.690000</td>\n",
       "      <td>6.890000</td>\n",
       "      <td>8.330000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>4.760000</td>\n",
       "      <td>7.140000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>3.570000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.420000</td>\n",
       "      <td>22.050000</td>\n",
       "      <td>2.170000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.104553     0.213015     0.280656     0.065425     0.312223   \n",
       "std       0.305358     1.290575     0.504143     1.395151     0.672513   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.420000     0.000000     0.380000   \n",
       "max       4.540000    14.280000     5.100000    42.810000    10.000000   \n",
       "\n",
       "                5            6            7            8            9   \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.095901     0.114208     0.105295     0.090067     0.239413   \n",
       "std       0.273824     0.391441     0.401071     0.278616     0.644755   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.160000   \n",
       "max       5.880000     7.270000    11.110000     5.260000    18.180000   \n",
       "\n",
       "                10           11           12           13           14  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.059824     0.541702     0.093930     0.058626     0.049205   \n",
       "std       0.201545     0.861698     0.301036     0.335184     0.258843   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.100000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.800000     0.000000     0.000000     0.000000   \n",
       "max       2.610000     9.670000     5.550000    10.000000     4.410000   \n",
       "\n",
       "                15           16           17           18           19  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.248848     0.142586     0.184745     1.662100     0.085577   \n",
       "std       0.825792     0.444055     0.531122     1.775481     0.509767   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     1.310000     0.000000   \n",
       "75%       0.100000     0.000000     0.000000     2.640000     0.000000   \n",
       "max      20.000000     7.140000     9.090000    18.750000    18.180000   \n",
       "\n",
       "                20           21           22           23           24  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.809761     0.121202     0.101645     0.094269     0.549504   \n",
       "std       1.200810     1.025756     0.350286     0.442636     1.671349   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.220000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.270000     0.000000     0.000000     0.000000     0.000000   \n",
       "max      11.110000    17.100000     5.450000    12.500000    20.830000   \n",
       "\n",
       "                25           26           27           28           29  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.265384     0.767305     0.124845     0.098915     0.102852   \n",
       "std       0.886955     3.367292     0.538576     0.593327     0.456682   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max      16.660000    33.330000     9.090000    14.280000     5.880000   \n",
       "\n",
       "                30           31           32           33           34  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.064753     0.047048     0.097229     0.047835     0.105412   \n",
       "std       0.403393     0.328559     0.555907     0.329445     0.532260   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max      12.500000     4.760000    18.180000     4.760000    20.000000   \n",
       "\n",
       "                35           36           37           38           39  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.097477     0.136953     0.013201     0.078629     0.064834   \n",
       "std       0.402623     0.423451     0.220651     0.434672     0.349916   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       7.690000     6.890000     8.330000    11.110000     4.760000   \n",
       "\n",
       "                40           41           42           43           44  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.043667     0.132339     0.046099     0.079196     0.301224   \n",
       "std       0.361205     0.766819     0.223812     0.621976     1.011687   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.110000   \n",
       "max       7.140000    14.280000     3.570000    20.000000    21.420000   \n",
       "\n",
       "                45           46           47           48           49  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.179824     0.005444     0.031869     0.038575     0.139030   \n",
       "std       0.911119     0.076274     0.285735     0.243471     0.270355   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.065000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.188000   \n",
       "max      22.050000     2.170000    10.000000     4.385000     9.752000   \n",
       "\n",
       "                50           51           52           53           54  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.016976     0.269071     0.075811     0.044238     5.191515   \n",
       "std       0.109394     0.815672     0.245882     0.429342    31.729449   \n",
       "min       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     1.588000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     2.276000   \n",
       "75%       0.000000     0.315000     0.052000     0.000000     3.706000   \n",
       "max       4.081000    32.478000     6.003000    19.829000  1102.500000   \n",
       "\n",
       "                55            56           57  \n",
       "count  4601.000000   4601.000000  4601.000000  \n",
       "mean     52.172789    283.289285     0.394045  \n",
       "std     194.891310    606.347851     0.488698  \n",
       "min       1.000000      1.000000     0.000000  \n",
       "25%       6.000000     35.000000     0.000000  \n",
       "50%      15.000000     95.000000     0.000000  \n",
       "75%      43.000000    266.000000     1.000000  \n",
       "max    9989.000000  15841.000000     1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the target variable\n",
    "\n",
    "Let's explore the dependent variable. Before feeding the data in a Neural Network, it will require one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4601.000000\n",
       "mean        0.394045\n",
       "std         0.488698\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         1.000000\n",
       "max         1.000000\n",
       "Name: 57, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Description of the classification variable\n",
    "df.iloc[:,57].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n",
      "no. classes: 171\n"
     ]
    }
   ],
   "source": [
    "print(set(df.iloc[:,57]))\n",
    "print('no. classes: ' + str(len(set(df[df.columns[1]]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4601, 2)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding\n",
    "\n",
    "classification = pd.get_dummies(df.iloc[:,57])\n",
    "print(classification.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I obtained a target dataframe, called `classification`, that contains the one-hot encoded version of my dependent binary variable. Now I can isolate the explanatory variables in my dataframe `df`. In order to do that I'll drop columns 0 and 1: the first is an index, the second is the target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.columns[57], axis=1)   # drop target column from explanatory df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4601, 57)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the shape is:\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training the model, I turn both explanatory and target data into numpy objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.values.astype(np.float64)\n",
    "classification = classification.values.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test split\n",
    "\n",
    "In an actual ML job, you would split your dataset in **Train**, **Validation** and **Test** sets. However, this is just an example on how to implement and run a Neural Network, so I'll skip that part and will split the data in train and test only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3450, 57)\n",
      "y_train shape: (3450, 2)\n",
      "\n",
      "X_test shape: (1151, 57)\n",
      "y_test shape: (1151, 2)\n"
     ]
    }
   ],
   "source": [
    "## TRAIN-TEST SPLIT\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, classification, test_size=0.25, random_state=173)\n",
    "\n",
    "print('X_train shape: ' + str(X_train.shape) + '\\ny_train shape: ' + str(y_train.shape))\n",
    "print('\\nX_test shape: ' + str(X_test.shape) + '\\ny_test shape: ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the variables must happen after the train-test split. That is because the test set must be scaled using the parameters of the training set: in real world cases you don't know what data you'll get from training, therefore this is the only way to truly understand the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the variables using Z-scores\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Neural Network architecture\n",
    "\n",
    "Since the network is not very deep, and the number of parameters is relatively small, I can employ more \"demanding\" (and performing) activation functions. In this case, I chose **ELU** (**Exponential Linear Unit**) activations. A **softmax** function is then applied at the end, so that the attribution of classes (\"spam\"/\"not-spam\") is shrinked into probabilities.\n",
    "\n",
    "Additionally, I apply **dropout** in order to prevent overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.activations import elu, softmax\n",
    "\n",
    "# Architecture\n",
    "n_input = X_train.shape[1]\n",
    "n_hidden1 = 30\n",
    "n_hidden2 = 30\n",
    "n_hidden3 = 15\n",
    "n_output = y_train.shape[1]\n",
    "\n",
    "# set dropout probability\n",
    "dropout_prob = 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The definition of a model in TensorFlow 2.0 follows the syntax of Keras' `Sequential()` models.\n",
    "\n",
    "Each layer is defined by the `Dense()` function, taking as inputs: the previous layer, the number of nodes, and the activation function (it can actually take a lor of additional arguments, but I'll not review them here). The input layer also requires a definition of the input data shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    Dense(n_input, input_shape = (n_input,), activation = elu),   # Input layer\n",
    "    \n",
    "    Dense(n_hidden1, activation = elu), # hidden layer 1\n",
    "    Dropout(dropout_prob), \n",
    "    \n",
    "    Dense(n_hidden2, activation = elu), # hidden layer 2\n",
    "    Dropout(dropout_prob), \n",
    "    \n",
    "    Dense(n_hidden3, activation = elu), # hidden layer 3\n",
    "    Dropout(dropout_prob), \n",
    "    \n",
    "    Dense(n_output, activation = softmax)  # Output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 57)                3306      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                1740      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 15)                465       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 32        \n",
      "=================================================================\n",
      "Total params: 6,473\n",
      "Trainable params: 6,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementation of Mini-Batch Gradient Descent\n",
    "\n",
    "In order to feed mini-batches of data into the Network at each iteration, I will write a function that takes a different subset of the main dataset at each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def fetch_batch(X, y, batch_size, epoch):\n",
    "    '''\n",
    "    Extracts a mini-batches of given size from a dataset.\n",
    "    WARNING: Requires a batch size that is multiple of the number of training epochs\n",
    "    \n",
    "    Returns: Train and Test Mini-Batches\n",
    "    '''\n",
    "    start = epoch*batch_size  # starting row of next mini-batch\n",
    "        \n",
    "    X_batch = X[start:start+batch_size, :]\n",
    "    y_batch = y[start:start+batch_size, :]\n",
    "    \n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the @tf.function decorator\n",
    "\n",
    "It's worth to spend few words on the **decorator @tf.function**. The decorator transform plain Python functions into TensorFlow's **graph code** (yeah, the underlying TensorFlow code is still in graph mode as in 1.x, you just can't see it now). This has the advantage to make it compatible with the module's functinos, and the make their runtime much faster.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll define the usual hyperparameters of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss: Binary cross-entropy is specific for binary classification tasks\n",
    "bce_loss = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "# Binary Accuracy (expressed in the [0,1] interval)\n",
    "accuracy = tf.keras.metrics.BinaryAccuracy()\n",
    "\n",
    "# Adam Optimizer (what you'll need 99.99% of the time)\n",
    "optimizer = tf.optimizers.Adam(learning_rate = 0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As [in the previous Notebook](https://github.com/IvanBongiorni/TensorFlow2.0_Tutorial/blob/master/TensorFlow2.0_01_basic_Classifier.ipynb), I'll use TensorFlow's **eager execution method**. Please refer to it for a more detailed explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fundamental element of training a Network in eager execution is represented by `tf.GradientTape()`. This object calculates and stores the gradient of the loss function at each iteration of the training operation. Once you generate a GradientTape, you can call the `.gradient()` argument to get the actual gradient (i.e. the first derivative of the loss function). Later, you feed this values into an `optimizer` using the `.apply_gradients` argument that updates the Network's trainable variables (the very act of \"learning\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of epochs: 69\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "n_epochs = len(X_train) // batch_size\n",
    "\n",
    "print('No. of epochs: ' + str(n_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.\tTraining Loss: 4.979808330535889,\tAccuracy: 0.84\n",
      "20.\tTraining Loss: 4.81271505355835,\tAccuracy: 0.78\n",
      "30.\tTraining Loss: 3.1986169815063477,\tAccuracy: 0.88\n",
      "40.\tTraining Loss: 2.1304428577423096,\tAccuracy: 0.92\n",
      "50.\tTraining Loss: 2.0643529891967773,\tAccuracy: 0.94\n",
      "60.\tTraining Loss: 2.1822969913482666,\tAccuracy: 0.92\n",
      "\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "###  TRAINING\n",
    "\n",
    "loss_history = []\n",
    "accuracy_history = []\n",
    "\n",
    "\n",
    "# I set a number of epochs that correspond to the number of mini-batches\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    # load the Mini-Batches\n",
    "    X_batch, y_batch = fetch_batch(X_train, y_train, batch_size, epoch)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        current_loss = bce_loss(model(X_batch), y_batch)  # take current loss\n",
    "    \n",
    "    gradients = tape.gradient(current_loss, model.trainable_variables)    # get the gradient of the loss function\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))  # update the weights\n",
    "    \n",
    "    loss_history.append(current_loss.numpy())   # save current loss in its history vector\n",
    "    \n",
    "    accuracy.update_state(y_batch, model(X_batch))  # compute current accuracy\n",
    "    current_accuracy = accuracy.result().numpy()  # save its result as numpy object\n",
    "    accuracy_history.append(current_accuracy)\n",
    "    \n",
    "    # To monitor progress, print loss and accuracy scores every 10 epochs\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(str(epoch+1) + '.\\tTraining Loss: ' + str(current_loss.numpy()) + ',\\tAccuracy: ' + str(current_accuracy))\n",
    "    \n",
    "    accuracy.reset_states()  # reset the state of accuracy object for next iteration\n",
    "#\n",
    "print('\\nTraining complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization\n",
    "\n",
    "Once the training is done, let's check the model's improvement visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using plt.subplot I can show paired loss and accuracy\n",
    "\n",
    "plt.figure(figsize = (15, 4))  # adjust figures size\n",
    "plt.subplots_adjust(wspace=0.2)  # adjust distance\n",
    "\n",
    "# loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(loss_history)\n",
    "plt.title('Loss History')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Binary Cross-Entropy')\n",
    "\n",
    "# accuracy plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(accuracy_history)\n",
    "plt.title('Accuracy History')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the main difference from full-Batch Gradient Descent is that the loss and accuracy histories look much more noisy. This was predictable, since at each iteration the model is trained only on a very small amount of data.\n",
    "\n",
    "At this point, Let's make a prediction on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)    # (Keras syntax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs a vector that contains the value of the class with the highest predicted probability\n",
    "prediction = np.argmax(prediction, axis=1)\n",
    "\n",
    "# so I do it also for the test data - i.e.: reverse one-hot encoding and get a vector of 0-1 values\n",
    "testdata = np.argmax(y_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[665  65]\n",
      " [ 37 384]]\n"
     ]
    }
   ],
   "source": [
    "# Now I can plot the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "CM = confusion_matrix(prediction, testdata)\n",
    "print(CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Confusion Matrix looks very good: oservations on the matrix diagonal are correct predictions. Luckily, only two datapoints have been misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9113814074717637\n"
     ]
    }
   ],
   "source": [
    "# Accuracy = sum of the diagonal / sum of the whole matrix\n",
    "\n",
    "print('Test Accuracy: ' + str(np.sum(np.diag(CM)) / np.sum(CM)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I like to visualize Confusion Matrices using a heatmap. IMHO, `seaborn` is the best Python library for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn\n",
    "\n",
    "seaborn.heatmap(CM, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, this was Mini-Batch Gradient Descent. In real world problems, you'll find this optimization techniques to be computationally much faster than full-Batch Gradient Descent.\n",
    "\n",
    "Most importantly, you'll likely achieve faster convergence of your Gradient. Even if full-Batch optimization can better approach the global minimum of your loss function, it might take eons to converge.\n",
    "That's why you often find Mini-Batch version of your optimization algorithm to achieve higher performances than its full-Batch counterpart (on a reasonable amount of training epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
